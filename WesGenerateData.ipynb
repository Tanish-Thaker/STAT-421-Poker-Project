{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f60f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import WesBotTWO as wb\n",
    "import HandOddsCalcWes as hoc\n",
    "\n",
    "import texasholdem as th\n",
    "import texasholdem.evaluator as eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79fc663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smort_decision(our_bot:PokerBot, game:th.TexasHoldEm)\n",
    "# actually make a goddamn decision using my scuffed bot thingy, and record\n",
    "# all the necessary information for Shro' to use in his thing\n",
    "# INPUTS:\n",
    "#   our_bot: a PokerBot object, supposed to be intelligent or something\n",
    "#   game:    a TexasHoldEm game object that we're playing\n",
    "# OUTPUT:\n",
    "#   a list containing:\n",
    "#     [hand_phase:str,\n",
    "#      my_hand:list of th.Card,\n",
    "#      board:list of th.Card,\n",
    "#      EV:float,\n",
    "#      my_chips_betting:int,\n",
    "#      their_chips_betting:int,\n",
    "#      my_decision:Decision]\n",
    "# SIDE EFFECT:\n",
    "#   makes the decision in the TexasHoldEm game object passed in\n",
    "def smort_decision(our_bot:wb.PokerBot, game:th.TexasHoldEm):\n",
    "  # get information regarding our hand, the game board, our win prob,\n",
    "  # their chips bet, and our EV\n",
    "  win_prob =  hoc.estimate_win_prob(game, game.current_player, 2, 1000)\n",
    "  loss_prob = 1 - win_prob\n",
    "  my_chips_betting = game.player_bet_amount(0)\n",
    "  their_chips_betting = game.player_bet_amount(1)\n",
    "  EV = win_prob*their_chips_betting - loss_prob*(my_chips_betting + \\\n",
    "                                                 game.chips_to_call(0))\n",
    "  # get features for Shro'\n",
    "  my_decision = our_bot.make_decision(EV, game)\n",
    "  my_hand = game.get_hand(game.current_player)\n",
    "  board = []\n",
    "  for card in game.board:\n",
    "    board.append(card)\n",
    "  # record hand phase\n",
    "  hand_phase = game.hand_phase.name\n",
    "  # actually make the decision\n",
    "  if (my_decision.type == \"RAISE\"):\n",
    "    if (game.validate_move(action = th.ActionType.RAISE,\\\n",
    "                           value = my_decision.size)):\n",
    "      game.take_action(th.ActionType.RAISE, my_decision.size)\n",
    "    else:\n",
    "      game.take_action(th.ActionType.ALL_IN)\n",
    "  elif (my_decision.type == \"CALL/CHECK\"):\n",
    "    if (game.validate_move(action = th.ActionType.CALL)):\n",
    "      game.take_action(th.ActionType.CALL)\n",
    "    else:\n",
    "      game.take_action(th.ActionType.CHECK)\n",
    "  elif (my_decision.type == \"FOLD\"):\n",
    "    game.take_action(th.ActionType.FOLD)\n",
    "  else:\n",
    "    game.take_action(th.ActionType.ALL_IN)\n",
    "  output = [hand_phase, my_hand, board, EV, my_chips_betting, their_chips_betting, my_decision]\n",
    "  return output\n",
    "\n",
    "# baby_decision(game:th.TexasHoldEm)\n",
    "# make a random decision for the opponent, just to get someone to play against\n",
    "# INPUTS:\n",
    "#   game: a th.TexasHoldEm object that we're playing\n",
    "# SIDE EFFECT:\n",
    "#   makes the random decision in the game object passed in\n",
    "def baby_decision(game:th.TexasHoldEm):\n",
    "  # make random decision\n",
    "  if (np.random.rand() > 0.5):\n",
    "    # baby gonna raise\n",
    "    min_raise = int(game.get_available_moves().raise_range.start)\n",
    "    max_raise = int(np.min([game.players[0].chips,\n",
    "                            game.get_available_moves().raise_range.stop]))\n",
    "    # make sure we only raise by some reasonable amount\n",
    "    max_raise = int((3*min_raise + max_raise) // 4)\n",
    "    if (max_raise - min_raise > 20):\n",
    "      max_raise = min_raise + 20\n",
    "    decision = \\\n",
    "      wb.Decision(\"RAISE\", int(np.random.uniform(min_raise, max_raise)))\n",
    "  else:\n",
    "    # baby gonna call/check\n",
    "    decision = wb.Decision(\"CALL/CHECK\")\n",
    "  # ensure validity of decision and actually make decision\n",
    "  if (decision.type == \"RAISE\" and\n",
    "      game.validate_move(action = th.ActionType.RAISE, value = decision.size)):\n",
    "    game.take_action(th.ActionType.RAISE, decision.size)\n",
    "    return -1\n",
    "  elif (game.validate_move(action = th.ActionType.CALL)):\n",
    "    game.take_action(th.ActionType.CALL)\n",
    "    return -1\n",
    "  elif (game.validate_move(action = th.ActionType.CHECK)):\n",
    "    game.take_action(th.ActionType.CHECK)\n",
    "    return -1\n",
    "  game.take_action(th.ActionType.FOLD)\n",
    "  return 0\n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84ecd6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [2:24:22<00:00,  1.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "our_bot = wb.PokerBot(maturity=epochs//4)\n",
    "\n",
    "rounds_list = []\n",
    "\n",
    "for i in trange(epochs):\n",
    "  game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "  game.start_hand()\n",
    "  current_round = []\n",
    "  while (game.is_hand_running()):\n",
    "    # branch on whose turn\n",
    "    if (game.current_player == 0):\n",
    "      our_decision = smort_decision(our_bot, game)\n",
    "      current_round.append(our_decision)\n",
    "      if (our_decision[6].type == \"FOLD\"):\n",
    "        who_won = 1\n",
    "      else:\n",
    "        who_won = -1\n",
    "    else:\n",
    "      who_won = baby_decision(game)\n",
    "    if (who_won == -1 and len(game.board) == 5):\n",
    "      jerry_hand_rank = eval.evaluate(game.get_hand(0), game.board)\n",
    "      tom_hand_rank = eval.evaluate(game.get_hand(1), game.board)\n",
    "      who_won = int(jerry_hand_rank >= tom_hand_rank)\n",
    "  # now round is done, close round and go again\n",
    "  won_or_lost_chips = game._get_last_pot().amount*((-1)**who_won)\n",
    "  our_bot.log_round(won_or_lost_chips)\n",
    "  rounds_list.append([current_round, won_or_lost_chips])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae83634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. outcomes: 13.913\n",
      "Avg. win rate: 0.295\n"
     ]
    }
   ],
   "source": [
    "outcomes = np.zeros(len(rounds_list))\n",
    "\n",
    "for i in range(len(rounds_list)):\n",
    "  outcomes[i] = rounds_list[i][1]\n",
    "\n",
    "print(\"Avg. outcomes:\", np.mean(outcomes))\n",
    "print(\"Avg. win rate:\", np.mean(outcomes > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e7061b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision: ['PREFLOP', [Card(\"4h\"), Card(\"6h\")], [], np.float64(-2.6400000000000006), 5, 20, <WesBotTWO.Decision object at 0x00000126D15F2750>]\n",
      "  Decision: ['FLOP', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\")], np.float64(0.0), 0, 0, <WesBotTWO.Decision object at 0x00000126C83FEA50>]\n",
      "    Decision: ['TURN', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\"), Card(\"4d\")], np.float64(0.0), 0, 0, <WesBotTWO.Decision object at 0x00000126C83FE270>]\n",
      "      Decision: ['TURN', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\"), Card(\"4d\")], np.float64(-1.6820000000000022), 10, 29, <WesBotTWO.Decision object at 0x00000126D15F1340>]\n",
      "        Decision: ['RIVER', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\"), Card(\"4d\"), Card(\"Th\")], np.float64(0.0), 0, 0, <WesBotTWO.Decision object at 0x00000126D15ED1F0>]\n",
      "          Decision: ['RIVER', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\"), Card(\"4d\"), Card(\"Th\")], np.float64(-3.1320000000000014), 11, 27, <WesBotTWO.Decision object at 0x00000126D15ED040>]\n",
      "            Decision: ['RIVER', [Card(\"4h\"), Card(\"6h\")], [Card(\"Ac\"), Card(\"Qd\"), Card(\"5h\"), Card(\"4d\"), Card(\"Th\")], np.float64(-9.211999999999996), 58, 94, <WesBotTWO.Decision object at 0x00000126D15EC5C0>]\n",
      "Outcome: 286\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, decision, children=None):\n",
    "        self.decision = decision\n",
    "        self.children = children if children else []\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, root, outcome):\n",
    "        self.root = root\n",
    "        self.outcome = outcome\n",
    "\n",
    "# Create decision trees from rounds_list\n",
    "decision_trees = []\n",
    "for round_entry in rounds_list:\n",
    "    decisions = round_entry[0]  # The list of decisions\n",
    "    outcome = round_entry[1]    # The outcome (tail of the entry)\n",
    "\n",
    "    # Build the tree structure\n",
    "    root = Node(decisions[0])  # First decision as the root\n",
    "    current_node = root\n",
    "    for decision in decisions[1:]:\n",
    "        new_node = Node(decision)\n",
    "        current_node.add_child(new_node)\n",
    "        current_node = new_node\n",
    "\n",
    "    decision_trees.append(DecisionTree(root, outcome))\n",
    "\n",
    "\n",
    "\n",
    "# Print the structure of the first tree\n",
    "def print_tree(node, depth=0):\n",
    "    print(\"  \" * depth + f\"Decision: {node.decision}\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, depth + 1)\n",
    "\n",
    "\n",
    "print_tree(decision_trees[0].root)\n",
    "print(\"Outcome:\", decision_trees[0].outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "064f3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1575 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1005        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010596716 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.00024    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.5e+04     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 1.13e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 926          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037755375 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00277      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.93e+04     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    value_loss           | 1.09e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 885         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006039583 |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.00559     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 1.09e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 860           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016265601 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.07         |\n",
      "|    explained_variance   | 0.0077        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.95e+04      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    value_loss           | 1.14e+05      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gymnasium import spaces, Env  # Use gymnasium instead of gym\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom environment for decision trees\n",
    "class DecisionTreeEnv(Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, decision_trees):\n",
    "        self.decision_trees = decision_trees\n",
    "        self.current_tree_idx = 0\n",
    "        self.current_node = None\n",
    "        self.action_space = spaces.Discrete(3)  # Example: 3 actions (RAISE, CALL, FOLD)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(7,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)  # Ensure compatibility with gymnasium\n",
    "        self.current_tree_idx = np.random.randint(len(self.decision_trees))\n",
    "        self.current_node = self.decision_trees[self.current_tree_idx].root\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Map action to decision\n",
    "        if action == 0:\n",
    "            decision = \"RAISE\"\n",
    "        elif action == 1:\n",
    "            decision = \"CALL/CHECK\"\n",
    "        else:\n",
    "            decision = \"FOLD\"\n",
    "\n",
    "        info = {}  # Additional information can be added here\n",
    "        reward = self.decision_trees[self.current_tree_idx].outcome\n",
    "        done = True  # End after one decision for simplicity\n",
    "        return self._get_observation(), reward, done, {\"decision\": decision}, info\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Convert the current node's decision into a numerical observation\n",
    "        hand_phase = self.current_node.decision[0]\n",
    "        my_hand = self.current_node.decision[1]\n",
    "        board = self.current_node.decision[2]\n",
    "        EV = self.current_node.decision[3]\n",
    "        my_chips_betting = self.current_node.decision[4]\n",
    "        their_chips_betting = self.current_node.decision[5]\n",
    "        decision_type = self.current_node.decision[6].type\n",
    "\n",
    "        # Map hand_phase and decision_type to numerical values\n",
    "        hand_phase_map = {\"PREFLOP\": 0, \"FLOP\": 1, \"TURN\": 2, \"RIVER\": 3}\n",
    "        decision_type_map = {\"RAISE\": 0, \"CALL/CHECK\": 1, \"FOLD\": 2}\n",
    "\n",
    "        hand_phase_num = hand_phase_map.get(hand_phase, -1)\n",
    "        decision_type_num = decision_type_map.get(decision_type, -1)\n",
    "\n",
    "        # Create the observation array\n",
    "        return np.array([\n",
    "            hand_phase_num,\n",
    "            len(my_hand),  # Number of cards in hand\n",
    "            len(board),    # Number of cards on the board\n",
    "            EV,\n",
    "            my_chips_betting,\n",
    "            their_chips_betting,\n",
    "            decision_type_num\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "# Wrap the environment\n",
    "env = DummyVecEnv([lambda: DecisionTreeEnv(decision_trees)])\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_decision_tree_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc390731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating games: 100%|██████████| 100/100 [02:26<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Bot Wins: 47\n",
      "PPO Bot Total Chips: 15323\n",
      "SMORT Bot Wins: 53\n",
      "SMORT Bot Total Chips: 15008.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # tqdm is already imported, but this ensures clarity\n",
    "\n",
    "# Reset metrics\n",
    "ppo_bot_wins = 0\n",
    "ppo_bot_chips = 0\n",
    "ppo_bot_decisions = []\n",
    "\n",
    "smort_bot_wins = 0\n",
    "smort_bot_chips = 0\n",
    "smort_bot_decisions = []\n",
    "\n",
    "total_games = 100  # Number of games to simulate\n",
    "\n",
    "for _ in tqdm(range(total_games), desc=\"Simulating games\"):\n",
    "    # Initialize a new game\n",
    "    game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "    game.start_hand()\n",
    "\n",
    "    while game.is_hand_running():\n",
    "        if game.current_player == 0:  # SMORT bot's turn\n",
    "            smort_decision_result = smort_decision(our_bot, game)\n",
    "            smort_bot_decisions.append(smort_decision_result)\n",
    "            if smort_decision_result[6].type == \"FOLD\":\n",
    "                who_won = 1  # PPO bot wins\n",
    "            else:\n",
    "                who_won = -1\n",
    "        else:  # PPO bot's turn\n",
    "            obs = env.reset()\n",
    "            action, _ = model.predict(obs)\n",
    "            decision = None\n",
    "            if action == 0:\n",
    "                EV = obs[0][3]  # Extract EV from observation\n",
    "                min_raise = int(game.get_available_moves().raise_range.start)\n",
    "                max_raise = int(np.min([game.players[0].chips, game.get_available_moves().raise_range.stop]))\n",
    "                raise_amount = int(min_raise + (max_raise - min_raise) * max(0, min(1, EV)))\n",
    "                decision = (th.ActionType.RAISE, raise_amount)\n",
    "            elif action == 1:\n",
    "                decision = (th.ActionType.CALL, None)\n",
    "            else:\n",
    "                decision = (th.ActionType.FOLD, None)\n",
    "\n",
    "            if decision[0] == th.ActionType.RAISE and game.validate_move(action=decision[0], value=decision[1]):\n",
    "                game.take_action(decision[0], decision[1])\n",
    "            elif decision[0] == th.ActionType.CALL and game.validate_move(action=decision[0]):\n",
    "                game.take_action(decision[0])\n",
    "            elif decision[0] == th.ActionType.FOLD:\n",
    "                game.take_action(decision[0])\n",
    "                who_won = 0  # SMORT bot wins\n",
    "            else:\n",
    "                # Ensure CHECK is only attempted when valid\n",
    "                if game.validate_move(action=th.ActionType.CHECK):\n",
    "                    game.take_action(th.ActionType.CHECK)\n",
    "                else:\n",
    "                    game.take_action(th.ActionType.FOLD)\n",
    "\n",
    "    # Determine the winner if the hand reaches showdown\n",
    "    if who_won == -1 and len(game.board) == 5:\n",
    "        jerry_hand_rank = eval.evaluate(game.get_hand(0), game.board)\n",
    "        tom_hand_rank = eval.evaluate(game.get_hand(1), game.board)\n",
    "        who_won = int(jerry_hand_rank >= tom_hand_rank)\n",
    "\n",
    "    # Update metrics\n",
    "    won_or_lost_chips = game._get_last_pot().amount * ((-1) ** who_won)\n",
    "    if who_won == 0:\n",
    "        ppo_bot_wins += 1\n",
    "        ppo_bot_chips += won_or_lost_chips\n",
    "    else:\n",
    "        smort_bot_wins += 1\n",
    "        smort_bot_chips += -won_or_lost_chips\n",
    "\n",
    "# Print metrics\n",
    "print(\"PPO Bot Wins:\", ppo_bot_wins)\n",
    "print(\"PPO Bot Total Chips:\", ppo_bot_chips)\n",
    "print(\"SMORT Bot Wins:\", smort_bot_wins)\n",
    "print(\"SMORT Bot Total Chips:\", smort_bot_chips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
