{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29bf86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import WesBot as wb\n",
    "import HandOddsCalcWes as hoc\n",
    "\n",
    "import texasholdem as th\n",
    "import texasholdem.evaluator as eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf5b082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Round:\n",
    "  def __init__(self):\n",
    "    self.decisions = []\n",
    "    self.outcome = int(0)\n",
    "  \n",
    "  def add_decision(self, decision:list):\n",
    "    self.decisions.append(decision)\n",
    "  \n",
    "  def close_round(self, outcome:int):\n",
    "    self.outcome = outcome\n",
    "  \n",
    "  def get_decisions(self):\n",
    "    return self.decisions\n",
    "  \n",
    "  def get_one_decision(self, index:int):\n",
    "    return self.decisions[index]\n",
    "  \n",
    "  def get_outcome(self):\n",
    "    return self.outcome\n",
    "  \n",
    "  def copy(self):\n",
    "    output = Round()\n",
    "    for decision in self.decisions:\n",
    "      output.add_decision(decision)\n",
    "    output.close_round(self.outcome)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3423fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smort_decision(our_bot:PokerBot, game:th.TexasHoldEm)\n",
    "# actually make a goddamn decision using my scuffed bot thingy, and record\n",
    "# all the necessary information for Shro' to use in his thing\n",
    "# INPUTS:\n",
    "#   our_bot: a PokerBot object, supposed to be intelligent or something\n",
    "#   game:    a TexasHoldEm game object that we're playing\n",
    "# OUTPUT:\n",
    "#   a list containing:\n",
    "#     [hand_phase:str,\n",
    "#      my_hand:list of th.Card,\n",
    "#      board:list of th.Card,\n",
    "#      EV:float,\n",
    "#      my_chips_betting:int,\n",
    "#      their_chips_betting:int,\n",
    "#      my_decision:Decision]\n",
    "# SIDE EFFECT:\n",
    "#   makes the decision in the TexasHoldEm game object passed in\n",
    "def smort_decision(our_bot:wb.PokerBot, game:th.TexasHoldEm):\n",
    "  # get information regarding our hand, the game board, our win prob,\n",
    "  # their chips bet, and our EV\n",
    "  win_prob, my_hand_odds = \\\n",
    "    hoc.estimate_win_and_hand_probs(game, game.current_player, 2, 1000)\n",
    "  loss_prob = 1 - win_prob\n",
    "  my_chips_betting = game.player_bet_amount(0) + game.chips_to_call(0)\n",
    "  their_chips_betting = game.player_bet_amount(1)\n",
    "  EV = win_prob*their_chips_betting - loss_prob*my_chips_betting\n",
    "  # get features for Shro'\n",
    "  my_decision = our_bot.make_decision(EV, my_hand_odds, game)\n",
    "  my_hand = game.get_hand(game.current_player)\n",
    "  board = []\n",
    "  for card in game.board:\n",
    "    board.append(card)\n",
    "  # record hand phase\n",
    "  hand_phase = game.hand_phase.name\n",
    "  # actually make the decision\n",
    "  if (my_decision.type == \"RAISE\"):\n",
    "    game.take_action(th.ActionType.RAISE, my_decision.size)\n",
    "  elif (my_decision.type == \"CALL/CHECK\"):\n",
    "    if (game.validate_move(action = th.ActionType.CALL)):\n",
    "      game.take_action(th.ActionType.CALL)\n",
    "    else:\n",
    "      game.take_action(th.ActionType.CHECK)\n",
    "  elif (my_decision.type == \"FOLD\"):\n",
    "    game.take_action(th.ActionType.FOLD)\n",
    "  else:\n",
    "    game.take_action(th.ActionType.ALL_IN)\n",
    "  output = [hand_phase, my_hand, board, EV, my_chips_betting, their_chips_betting, my_decision]\n",
    "  return output\n",
    "\n",
    "# baby_decision(game:th.TexasHoldEm)\n",
    "# make a random decision for the opponent, just to get someone to play against\n",
    "# INPUTS:\n",
    "#   game: a th.TexasHoldEm object that we're playing\n",
    "# SIDE EFFECT:\n",
    "#   makes the random decision in the game object passed in\n",
    "def baby_decision(game:th.TexasHoldEm):\n",
    "  # opponent makes random decision (reused baby code)\n",
    "  babys_decision = np.random.choice(3)\n",
    "  if (babys_decision == 0):\n",
    "    # baby will call/check if possible\n",
    "    if (game.validate_move(action = th.ActionType.CALL) or\n",
    "        game.validate_move(action = th.ActionType.CHECK)):\n",
    "      decision = wb.Decision(\"CALL/CHECK\")\n",
    "    elif (game.validate_move(action = th.ActionType.ALL_IN)):\n",
    "      decision = wb.Decision(\"ALLIN\")\n",
    "    else:\n",
    "      decision = wb.Decision(\"FOLD\")\n",
    "  elif (babys_decision == 1):\n",
    "    # baby will fold\n",
    "    decision = wb.Decision(\"FOLD\")\n",
    "  else:\n",
    "    # baby will raise if possible\n",
    "    min_raise = game.get_available_moves().raise_range.start\n",
    "    max_raise = int(np.min([game.players[game.current_player].chips,\n",
    "                            game.get_available_moves().raise_range.stop]))\n",
    "    if (min_raise <= max_raise and\n",
    "        game.validate_move(action = th.ActionType.RAISE, value = min_raise) and\n",
    "        game.validate_move(action = th.ActionType.RAISE, value = max_raise)):\n",
    "      decision = \\\n",
    "        wb.Decision(\"RAISE\", int(np.random.uniform(min_raise, max_raise)))\n",
    "    elif (game.validate_move(action = th.ActionType.CALL) or\n",
    "          game.validate_move(action = th.ActionType.CHECK)):\n",
    "      decision = wb.Decision(\"CALL/CHECK\")\n",
    "    elif (game.validate_move(action = th.ActionType.ALL_IN)):\n",
    "      decision = wb.Decision(\"ALLIN\")\n",
    "    else:\n",
    "      decision = wb.Decision(\"FOLD\")\n",
    "  # actually make the decision\n",
    "  if (decision.type == \"RAISE\"):\n",
    "    game.take_action(th.ActionType.RAISE, decision.size)\n",
    "  elif (decision.type == \"CALL/CHECK\"):\n",
    "    if (game.validate_move(action = th.ActionType.CALL)):\n",
    "      game.take_action(th.ActionType.CALL)\n",
    "    else:\n",
    "      game.take_action(th.ActionType.CHECK)\n",
    "  elif (decision.type == \"FOLD\"):\n",
    "    game.take_action(th.ActionType.FOLD)\n",
    "    return 0\n",
    "  else:\n",
    "    game.take_action(th.ActionType.ALL_IN)\n",
    "  return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a7deb",
   "metadata": {},
   "source": [
    "# This loop is outdated now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76429652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "# game.start_hand()\n",
    "# current_round = Round()\n",
    "\n",
    "\n",
    "# epochs = 1000\n",
    "# our_bot = wb.PokerBot(k=50, EV_weight=10.0, maturity=epochs//4)\n",
    "\n",
    "\n",
    "\n",
    "# rounds_list = [] # a list of Round objects\n",
    "\n",
    "# for i in trange(epochs):\n",
    "\n",
    "#   if (game.is_hand_running()):\n",
    "#     # control flow time! we are player 0.\n",
    "#     if (game.current_player == 0):\n",
    "#       # make decision and record decision\n",
    "#       our_decision = smort_decision(our_bot, game)\n",
    "#       current_round.add_decision(our_decision)\n",
    "#       if (our_decision[6].type == \"FOLD\"):\n",
    "#         who_won = 1\n",
    "#     else:\n",
    "#       # the opponent (who is baby) makes a decision\n",
    "#       # this also sees if baby folded. If he did, it sets who_won to 0\n",
    "#       who_won = baby_decision(game)\n",
    "\n",
    "#   # ensure a game and hand is running\n",
    "#   if (not game.is_game_running()):\n",
    "#     game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "#     game.start_hand()\n",
    "#     current_round = Round()\n",
    "#   # start a new hand if needed\n",
    "#   if (not game.is_hand_running()):\n",
    "#     current_round.close_round(game._get_last_pot().amount*((-1)**who_won))\n",
    "#     rounds_list.append(current_round.copy())\n",
    "#     game.start_hand()\n",
    "#     current_round = Round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f34952",
   "metadata": {},
   "source": [
    "# Trying the loop again, without the Round object. Also, try using more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c45789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [1:27:58<00:00, 18.95it/s] \n"
     ]
    }
   ],
   "source": [
    "game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "game.start_hand()\n",
    "current_round = []\n",
    "\n",
    "\n",
    "epochs = 100000\n",
    "our_bot = wb.PokerBot(k=500, EV_weight=10.0, maturity=epochs//4)\n",
    "\n",
    "\n",
    "\n",
    "rounds_list = [] # a list of Round objects\n",
    "\n",
    "for i in trange(epochs):\n",
    "\n",
    "  if (game.is_hand_running()):\n",
    "    # control flow time! we are player 0.\n",
    "    if (game.current_player == 0):\n",
    "      # make decision and record decision\n",
    "      our_decision = smort_decision(our_bot, game)\n",
    "      # current_round.add_decision(our_decision)\n",
    "      current_round.append(our_decision)\n",
    "      if (our_decision[6].type == \"FOLD\"):\n",
    "        who_won = 1\n",
    "    else:\n",
    "      # the opponent (who is baby) makes a decision\n",
    "      # this also sees if baby folded. If he did, it sets who_won to 0\n",
    "      who_won = baby_decision(game)\n",
    "\n",
    "  # ensure a game and hand is running\n",
    "  if (not game.is_game_running()):\n",
    "    game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "    game.start_hand()\n",
    "    current_round = []\n",
    "  # start a new hand if needed\n",
    "  if (not game.is_hand_running()):\n",
    "    # current_round.close_round(game._get_last_pot().amount*((-1)**who_won))\n",
    "    won_or_lost_chips = game._get_last_pot().amount*((-1)**who_won)\n",
    "    rounds_list.append([current_round, won_or_lost_chips])\n",
    "    game.start_hand()\n",
    "    current_round = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f92ae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               decisions  outcomes\n",
      "0      [[PREFLOP, [Qh, 7h], [], 0.7699999999999996, 5...       -10\n",
      "1      [[PREFLOP, [Ad, Ts], [], 1.21, 5, 5, <WesBot.D...       476\n",
      "2                                                     []         7\n",
      "3      [[PREFLOP, [2s, 9s], [], -0.56, 5, 5, <WesBot....        10\n",
      "4                                                     []         7\n",
      "...                                                  ...       ...\n",
      "37624  [[PREFLOP, [7s, 5c], [], -0.77, 5, 5, <WesBot....       626\n",
      "37625  [[PREFLOP, [Js, 3d], [], -2.309999999999995, 3...       -70\n",
      "37626  [[PREFLOP, [5d, 9d], [], 0.03000000000000025, ...       -70\n",
      "37627  [[PREFLOP, [Td, Ad], [], 29.84800000000001, 91...      -161\n",
      "37628  [[PREFLOP, [3d, 2d], [], -1.21, 5, 5, <WesBot....        -7\n",
      "\n",
      "[37629 rows x 2 columns]\n",
      "Total Earnings: -1857342\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with decisions and outcomes\n",
    "data = {\n",
    "    \"decisions\": [round_obj[0] for round_obj in rounds_list],  # Extract decisions (first element of each sublist)\n",
    "    \"outcomes\": [round_obj[1] for round_obj in rounds_list]   # Extract outcomes (second element of each sublist)\n",
    "}\n",
    "decisions_outcomes_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(decisions_outcomes_df)\n",
    "\n",
    "# Calculate total earnings\n",
    "total_earnings = decisions_outcomes_df['outcomes'].sum()\n",
    "print(f\"Total Earnings: {total_earnings}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb82d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: 10\n",
      "  Decision: {'hand_phase': 'PREFLOP', 'my_hand': [Card(\"2s\"), Card(\"9s\")], 'board': [], 'EV': -0.56, 'my_chips_betting': 5, 'their_chips_betting': 5, 'my_decision': <WesBot.Decision object at 0x0000019D242D4FE0>}\n"
     ]
    }
   ],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, decision=None, outcome=None):\n",
    "        self.decision = decision\n",
    "        self.outcome = outcome\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.outcome is not None:\n",
    "            return f\"Outcome: {self.outcome}\"\n",
    "        return f\"Decision: {self.decision}\"\n",
    "\n",
    "\n",
    "def format_decision(decision):\n",
    "    return {\n",
    "        \"hand_phase\": decision[0],\n",
    "        \"my_hand\": decision[1],\n",
    "        \"board\": decision[2],\n",
    "        \"EV\": round(float(decision[3]), 4),\n",
    "        \"my_chips_betting\": decision[4],\n",
    "        \"their_chips_betting\": decision[5],\n",
    "        \"my_decision\": decision[6]\n",
    "    }\n",
    "\n",
    "def build_decision_tree_with_format(row):\n",
    "    # Start with the outcome as the root node\n",
    "    root = DecisionNode(outcome=row['outcomes'])\n",
    "    current_node = root\n",
    "\n",
    "    # Traverse the decisions in order\n",
    "    for decision in row['decisions']:\n",
    "        formatted_decision = format_decision(decision)\n",
    "        new_node = DecisionNode(decision=formatted_decision)\n",
    "        current_node.add_child(new_node)\n",
    "        current_node = new_node  # Move to the new node for the next decision\n",
    "\n",
    "    return root\n",
    "\n",
    "# Build decision trees with formatted decisions for all rows in the DataFrame\n",
    "formatted_decision_trees = [build_decision_tree_with_format(row) for _, row in decisions_outcomes_df.iterrows()]\n",
    "\n",
    "def print_tree(node, level=0):\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{node}\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, level + 1)\n",
    "\n",
    "# Print the entire tree for the first formatted decision tree\n",
    "print_tree(formatted_decision_trees[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80c280ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1423 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003622172 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 3.67e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.000264   |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 822          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038859574 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.54         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000466    |\n",
      "|    value_loss           | 4.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 797          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043743164 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.000122     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.01         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000265    |\n",
      "|    value_loss           | 372          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 781       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0057638 |\n",
      "|    clip_fraction        | 0.0112    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.09     |\n",
      "|    explained_variance   | -4.16e-05 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.57      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.00078  |\n",
      "|    value_loss           | 242       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x19d270fa960>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import stable_baselines3 without manually defining a __version__ attribute\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from gymnasium import spaces, Env  # Ensure gymnasium is used for spaces and Env\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom environment for reinforcement learning\n",
    "class PokerEnv(Env):\n",
    "    def __init__(self, decision_trees):\n",
    "        super(PokerEnv, self).__init__()\n",
    "        self.decision_trees = decision_trees\n",
    "        self.current_tree_index = 0\n",
    "        self.current_node = None\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Actions: 0 = Fold, 1 = Call/Check, 2 = Raise\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Observations: EV, my_chips_betting, their_chips_betting\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(3,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Handle the seed argument if provided\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        # Reset to the root of the next decision tree\n",
    "        self.current_tree_index = (self.current_tree_index + 1) % len(self.decision_trees)\n",
    "        self.current_node = self.decision_trees[self.current_tree_index]\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulate the action and move to the next node\n",
    "        if len(self.current_node.children) > 0:\n",
    "            self.current_node = self.current_node.children[0]  # Move to the first child for simplicity\n",
    "        else:\n",
    "            done = True\n",
    "            reward = self.current_node.outcome\n",
    "            return self._get_observation(), reward, done, False, {}\n",
    "\n",
    "        # Calculate reward based on the outcome\n",
    "        reward = self.current_node.outcome if self.current_node.outcome is not None else 0\n",
    "        done = len(self.current_node.children) == 0\n",
    "        return self._get_observation(), reward, done, False, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Extract relevant features from the current node\n",
    "        if self.current_node.decision is not None:\n",
    "            return np.array([\n",
    "                self.current_node.decision[\"EV\"],\n",
    "                self.current_node.decision[\"my_chips_betting\"],\n",
    "                self.current_node.decision[\"their_chips_betting\"]\n",
    "            ], dtype=np.float32)\n",
    "        else:\n",
    "            return np.zeros(3, dtype=np.float32)\n",
    "\n",
    "# Create the environment using the formatted decision trees\n",
    "env = DummyVecEnv([lambda: PokerEnv(formatted_decision_trees)])\n",
    "\n",
    "# Train a PPO model on the environment\n",
    "ppo_model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "ppo_model.learn(total_timesteps=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "100c1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:59<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "Total games played: 1000\n",
      "Model wins: 0\n",
      "Total earnings: -114842\n",
      "Model win rate: 0.00\n",
      "Model earnings per game: -114.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics for tracking total earnings and win rate\n",
    "metrics = {\n",
    "    \"total_earnings\": 0,\n",
    "    \"model_win_rate\": 0.0\n",
    "}\n",
    "\n",
    "model_wins = 0  # Counter for model's wins\n",
    "total_games = 0  # Counter for total games played\n",
    "\n",
    "epochs = 1000  # Number of epochs for simulation\n",
    "rounds_list = []  # List to store rounds\n",
    "\n",
    "# Simulate games between the RL model and the smart bot\n",
    "for epoch in trange(epochs):\n",
    "    # Ensure a game and hand are running\n",
    "    game = th.TexasHoldEm(buyin=500, big_blind=5, small_blind=2, max_players=2)\n",
    "    game.start_hand()\n",
    "    while not game.is_hand_running():\n",
    "        game.start_hand()\n",
    "\n",
    "    current_round = Round()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if game.current_player == 0:\n",
    "            # RL model's turn\n",
    "            obs = env.reset()\n",
    "            action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "            if random.random() == 0:\n",
    "                if game.validate_move(action=th.ActionType.ALL_IN):\n",
    "                    game.take_action(th.ActionType.ALL_IN)\n",
    "                else:\n",
    "                    game.take_action(th.ActionType.FOLD)  # Fallback action\n",
    "            elif action == 0:\n",
    "                if game.validate_move(action=th.ActionType.FOLD):\n",
    "                    game.take_action(th.ActionType.FOLD)\n",
    "            elif action == 1:\n",
    "                if game.validate_move(action=th.ActionType.CALL):\n",
    "                    game.take_action(th.ActionType.CALL)\n",
    "                elif game.validate_move(action=th.ActionType.CHECK):\n",
    "                    game.take_action(th.ActionType.CHECK)\n",
    "                else:\n",
    "                    game.take_action(th.ActionType.FOLD)  # Fallback action\n",
    "            elif action == 2:\n",
    "                min_raise = game.get_available_moves().raise_range.start\n",
    "                max_raise = int(np.min([game.players[game.current_player].chips,\n",
    "                                        game.get_available_moves().raise_range.stop]))\n",
    "                if min_raise > max_raise or min_raise <= 0:\n",
    "                    # Fallback to a valid action if min_raise is invalid\n",
    "                    if game.validate_move(action=th.ActionType.CALL):\n",
    "                        game.take_action(th.ActionType.CALL)\n",
    "                    elif game.validate_move(action=th.ActionType.CHECK):\n",
    "                        game.take_action(th.ActionType.CHECK)\n",
    "                    else:\n",
    "                        game.take_action(th.ActionType.FOLD)\n",
    "                else:\n",
    "                    if game.validate_move(action=th.ActionType.RAISE, value=min_raise):\n",
    "                        game.take_action(th.ActionType.RAISE, min_raise)\n",
    "                    else:\n",
    "                        game.take_action(th.ActionType.FOLD)  # Fallback action\n",
    "            else:\n",
    "                if game.validate_move(action=th.ActionType.ALL_IN):\n",
    "                    game.take_action(th.ActionType.ALL_IN)\n",
    "                else:\n",
    "                    game.take_action(th.ActionType.FOLD)  # Fallback action\n",
    "        else:\n",
    "            # Smart bot's turn\n",
    "            # Smart bot decision\n",
    "            smort_decision(our_bot, game)\n",
    "            who_won = 0 if game.current_player == 1 else 1  # Determine the winner based on the current player\n",
    "\n",
    "        if not game.is_hand_running():\n",
    "            done = True\n",
    "    outcome = game._get_last_pot().amount * (-1 if who_won == 1 else 1)\n",
    "    # Record the outcome\n",
    "    outcome = game._get_last_pot().amount * ((-1) ** who_won)\n",
    "    current_round.close_round(outcome)\n",
    "    rounds_list.append(current_round.copy())\n",
    "\n",
    "    # Update metrics\n",
    "    total_games += 1\n",
    "    if who_won == 0:\n",
    "        model_wins += 1\n",
    "    metrics[\"total_earnings\"] += outcome\n",
    "    metrics[\"model_win_rate\"] = model_wins / total_games\n",
    "\n",
    "# Print the final metrics\n",
    "print(f\"Final Metrics:\")\n",
    "print(f\"Total games played: {total_games}\")\n",
    "print(f\"Model wins: {model_wins}\")\n",
    "print(f\"Total earnings: {metrics['total_earnings']}\")\n",
    "print(f\"Model win rate: {metrics['model_win_rate']:.2f}\")\n",
    "print(f\"Model earnings per game: {metrics['total_earnings'] / total_games:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "160e55fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 603      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.992   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.36    |\n",
      "|    value_loss         | 0.169    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 583      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0.0285   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 8.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 587      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.0248   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    value_loss         | 9.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 2.71      |\n",
      "|    value_loss         | 18        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -2.81e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.213    |\n",
      "|    value_loss         | 0.0635    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.433   |\n",
      "|    value_loss         | 0.156    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.0473   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.989   |\n",
      "|    explained_variance | -35.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.283   |\n",
      "|    value_loss         | 0.0824   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 9.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -4.64    |\n",
      "|    value_loss         | 169      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -3.71e+16 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.173    |\n",
      "|    value_loss         | 0.0535    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -2.56e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -0.28     |\n",
      "|    value_loss         | 0.0879    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 3.83     |\n",
      "|    value_loss         | 27       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.93    |\n",
      "|    explained_variance | 0.0137   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.458    |\n",
      "|    value_loss         | 9.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.959   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.139   |\n",
      "|    value_loss         | 0.0403   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.75    |\n",
      "|    explained_variance | 0.0202   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 3.47     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | 0.0766   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.113    |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.488   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.014    |\n",
      "|    value_loss         | 0.0561   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.235   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.00618 |\n",
      "|    value_loss         | 0.083    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.265   |\n",
      "|    explained_variance | 0.0277   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0119   |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'stable_baselines3' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m a2c_model.learn(total_timesteps=\u001b[32m10000\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save the new model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43ma2c_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpoker_a2c_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Replace the existing model with the new A2C model for evaluation\u001b[39;00m\n\u001b[32m     11\u001b[39m model = a2c_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\STAT-421-Poker-Project\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:867\u001b[39m, in \u001b[36mBaseAlgorithm.save\u001b[39m\u001b[34m(self, path, exclude, include)\u001b[39m\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# Build dict of state_dicts\u001b[39;00m\n\u001b[32m    865\u001b[39m params_to_save = \u001b[38;5;28mself\u001b[39m.get_parameters()\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m \u001b[43msave_to_zip_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_to_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytorch_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpytorch_variables\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\STAT-421-Poker-Project\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:333\u001b[39m, in \u001b[36msave_to_zip_file\u001b[39m\u001b[34m(save_path, data, params, pytorch_variables, verbose)\u001b[39m\n\u001b[32m    331\u001b[39m     archive.writestr(\u001b[33m\"\u001b[39m\u001b[33m_stable_baselines3_version\u001b[39m\u001b[33m\"\u001b[39m, sb3.__version__)\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# Save system info about the current python env\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     archive.writestr(\u001b[33m\"\u001b[39m\u001b[33msystem_info.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mget_system_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprint_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m])\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(save_path, (\u001b[38;5;28mstr\u001b[39m, pathlib.Path)):\n\u001b[32m    336\u001b[39m     file.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\STAT-421-Poker-Project\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\utils.py:536\u001b[39m, in \u001b[36mget_system_info\u001b[39m\u001b[34m(print_info)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_system_info\u001b[39m(print_info: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    524\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    525\u001b[39m \u001b[33;03m    Retrieve system and python env info for the current system.\u001b[39;00m\n\u001b[32m    526\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    529\u001b[39m \u001b[33;03m        and a formatted string.\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m     env_info = {\n\u001b[32m    532\u001b[39m         \u001b[38;5;66;03m# In OS, a regex is used to add a space between a \"#\" and a number to avoid\u001b[39;00m\n\u001b[32m    533\u001b[39m         \u001b[38;5;66;03m# wrongly linking to another issue on GitHub. Example: turn \"#42\" to \"# 42\".\u001b[39;00m\n\u001b[32m    534\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOS\u001b[39m\u001b[33m\"\u001b[39m: re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m#(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m# \u001b[39m\u001b[33m\\\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform.platform()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform.version()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m    535\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPython\u001b[39m\u001b[33m\"\u001b[39m: platform.python_version(),\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mStable-Baselines3\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43msb3\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__version__\u001b[49m,\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPyTorch\u001b[39m\u001b[33m\"\u001b[39m: th.__version__,\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGPU Enabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(th.cuda.is_available()),\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNumpy\u001b[39m\u001b[33m\"\u001b[39m: np.__version__,\n\u001b[32m    540\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCloudpickle\u001b[39m\u001b[33m\"\u001b[39m: cloudpickle.__version__,\n\u001b[32m    541\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGymnasium\u001b[39m\u001b[33m\"\u001b[39m: gym.__version__,\n\u001b[32m    542\u001b[39m     }\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    544\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgym\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai_gym\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'stable_baselines3' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "# Create and train the A2C model\n",
    "a2c_model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "a2c_model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the new model\n",
    "a2c_model.save(\"poker_a2c_model\")\n",
    "\n",
    "# Replace the existing model with the new A2C model for evaluation\n",
    "model = a2c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d6895",
   "metadata": {},
   "source": [
    "# AFTER THIS POINT, NOTHING IS IN USE AND ONLY REMAINS FOR REFERENCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1aefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFLOP\n"
     ]
    }
   ],
   "source": [
    "print(game.hand_phase.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(game.current_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01752d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Card(\"3c\"), Card(\"4d\")] [] 0.402 5 -155.862\n"
     ]
    }
   ],
   "source": [
    "# get information regarding our hand, the game board, our win prob, their chips bet, and our EV\n",
    "win_prob, my_hand_odds = hoc.estimate_win_and_hand_probs(game, 0, 2, 1000)\n",
    "loss_prob = 1 - win_prob\n",
    "my_chips_betting = game.player_bet_amount(0) + game.chips_to_call(0)\n",
    "their_chips_betting = game.player_bet_amount(1)\n",
    "EV = win_prob*their_chips_betting - loss_prob*my_chips_betting\n",
    "print(game.get_hand(0), game.board, win_prob, their_chips_betting, EV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afcb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n"
     ]
    }
   ],
   "source": [
    "# get decision\n",
    "my_decision = our_bot.make_decision(EV, my_hand_odds, game)\n",
    "print(my_decision.type, my_decision.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually make decision\n",
    "if (my_decision.type == \"RAISE\"):\n",
    "  game.take_action(th.ActionType.RAISE, my_decision.size)\n",
    "elif (my_decision.type == \"CALL/CHECK\"):\n",
    "  if (game.validate_move(action = th.ActionType.CALL)):\n",
    "    game.take_action(th.ActionType.CALL)\n",
    "  else:\n",
    "    game.take_action(th.ActionType.CHECK)\n",
    "elif (my_decision.type == \"FOLD\"):\n",
    "  game.take_action(th.ActionType.FOLD)\n",
    "else:\n",
    "  game.take_action(th.ActionType.ALL_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL/CHECK 0\n"
     ]
    }
   ],
   "source": [
    "# opponent makes random decision (reused baby code)\n",
    "babys_decision = np.random.choice(3)\n",
    "if (babys_decision == 0):\n",
    "  # baby will call/check if possible\n",
    "  if (game.validate_move(action = th.ActionType.CALL) or\n",
    "      game.validate_move(action = th.ActionType.CHECK)):\n",
    "    decision = wb.Decision(\"CALL/CHECK\")\n",
    "  elif (game.validate_move(game.current_player, th.ActionType.ALL_IN)):\n",
    "    decision = wb.Decision(\"ALLIN\")\n",
    "  else:\n",
    "    decision = wb.Decision(\"FOLD\")\n",
    "elif (babys_decision == 1):\n",
    "  # baby will fold\n",
    "  decision = wb.Decision(\"FOLD\")\n",
    "else:\n",
    "  # baby will raise if possible\n",
    "  min_raise = game.get_available_moves().raise_range[0]\n",
    "  max_raise = int(np.min([game.players[game.current_player].chips,\n",
    "                          game.get_available_moves().raise_range[-1]]))\n",
    "  if (min_raise <= max_raise and\n",
    "      game.validate_move(action = th.ActionType.RAISE, value = min_raise) and\n",
    "      game.validate_move(action = th.ActionType.RAISE, value = max_raise)):\n",
    "    decision = \\\n",
    "      wb.Decision(\"RAISE\", int(np.random.uniform(min_raise, max_raise)))\n",
    "  elif (game.validate_move(action = th.ActionType.CALL) or\n",
    "        game.validate_move(action = th.ActionType.CHECK)):\n",
    "    decision = wb.Decision(\"CALL/CHECK\")\n",
    "  elif (game.validate_move(action = th.ActionType.ALL_IN)):\n",
    "    decision = wb.Decision(\"ALLIN\")\n",
    "  else:\n",
    "    decision = wb.Decision(\"FOLD\")\n",
    "print(decision.type, decision.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8d729",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No hand is running",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     game.take_action(th.ActionType.CALL)\n\u001b[32m      7\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mgame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mActionType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHECK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (decision.type == \u001b[33m\"\u001b[39m\u001b[33mFOLD\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     10\u001b[39m   game.take_action(th.ActionType.FOLD)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\STAT-421-Poker-Project\\.venv\\Lib\\site-packages\\texasholdem\\game\\game.py:1117\u001b[39m, in \u001b[36mTexasHoldEm.take_action\u001b[39m\u001b[34m(self, action_type, value, total)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1103\u001b[39m \u001b[33;03mThe current player takes the specified action.\u001b[39;00m\n\u001b[32m   1104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m \n\u001b[32m   1115\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_hand_running():\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo hand is running\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total \u001b[38;5;129;01mand\u001b[39;00m value:\n\u001b[32m   1120\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGot arguments for both total and value. Expected only one.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1122\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No hand is running"
     ]
    }
   ],
   "source": [
    "# actually make decision\n",
    "if (decision.type == \"RAISE\"):\n",
    "  game.take_action(th.ActionType.RAISE, decision.size)\n",
    "elif (decision.type == \"CALL/CHECK\"):\n",
    "  if (game.validate_move(action = th.ActionType.CALL)):\n",
    "    game.take_action(th.ActionType.CALL)\n",
    "  else:\n",
    "    game.take_action(th.ActionType.CHECK)\n",
    "elif (decision.type == \"FOLD\"):\n",
    "  game.take_action(th.ActionType.FOLD)\n",
    "else:\n",
    "  game.take_action(th.ActionType.ALL_IN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
